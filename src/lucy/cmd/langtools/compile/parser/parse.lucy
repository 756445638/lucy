import "lucy/cmd/langtools/compile/ast"
import "lucy/cmd/langtools/compile/lex"
import "lucy/cmd/langtools/compile/jvm/cg"

public fn Parse(
	tops []ast.TopNode,
	filename string,
	bs []byte,
	onlyParseImport bool,
	nErrors2Stop int) -> (errs []error) {
	
	p := new Parser(bs , tops , filename , onlyParseImport , nErrors2Stop  )
	
	
	return p.parse()
}

class Parser {
	onlyParseImport        bool
	bs                     []byte
	tops                   []ast.TopNode
	lexer                  lex.Lexer
	filename               string
	lastToken              lex.Token
	token                  lex.Token
	errs                   []error
	nErrors2Stop           int
	consumeFoundValidToken bool
	ExpressionParser       ExpressionParser
	FunctionParser         FunctionParser
	ClassParser            ClassParser
	BlockParser            BlockParser
	TypeParser             TypeParser 
	EnumParser             EnumParser


	/*
		call before parse source file
	*/
	fn Parser(bs []byte , tops []ast.TopNode ,filename string , onlyParseImport bool ,nErrors2Stop int ) {
	    this.super()
		this.ExpressionParser = new ExpressionParser(this)
		this.FunctionParser = new FunctionParser(this)
		this.TypeParser = new TypeParser(this)
		this.ClassParser = new ClassParser(this)
		this.BlockParser = new BlockParser(this)
		this.EnumParser = new EnumParser(this)
		this.errs = []error{}
		this.bs = bs
		this.tops = tops
		this.filename = filename
		this.onlyParseImport = onlyParseImport
		this.nErrors2Stop = nErrors2Stop
	}

	fn parse() -> (errs []error ) {
		this.lexer = lex.New(this.bs, 1, 1)
		this.Next(lfNotToken) //
		if this.token.Type == lex.TokenEof {
			return null
		}
		for _, t := range this.parseImports() {
			this.tops.append( new ast.TopNode(t))
		}
		if this.onlyParseImport { // only parse imports
			return this.errs
		}
		var accessControlToken lex.Token
		isFinal := false
		isAbstract := false
		var finalPos ast.Pos
		comment := new CommentParser(this)
		fn resetProperty () {
			accessControlToken = null
			isFinal = false
			isAbstract = false
			finalPos = null
			comment.reset()
		}
		fn isPublic () -> (is bool) {
			return accessControlToken != null && accessControlToken.Type == lex.TokenPublic
		}
		for this.token.Type != lex.TokenEof {
			if len(this.errs) > this.nErrors2Stop {
				break
			}
			switch this.token.Type {
			case lex.TokenComment, lex.TokenMultiLineComment:
				comment.read()
			case lex.TokenSemicolon, lex.TokenLf: // empty statement, no big deal
				this.Next(lfNotToken)
				continue
			case lex.TokenPublic:
				accessControlToken = this.token
				this.Next(lfIsToken)
				this.unExpectNewLineAndSkip()
				if err := this.validAfterPublic(); err != null {
					accessControlToken = null
				}
				continue
			case lex.TokenAbstract:
				this.Next(lfIsToken)
				this.unExpectNewLineAndSkip()
				if err := this.validAfterAbstract(); err == null {
					isAbstract = true
				}
			case lex.TokenFinal:
				pos := this.mkPos()
				this.Next(lfIsToken)
				this.unExpectNewLineAndSkip()
				if err := this.validAfterFinal(); err != null {
					isFinal = false
				} else {
					isFinal = true
					finalPos = pos
				}
				continue
			case lex.TokenVar:
				pos := this.mkPos()
				this.Next(lfIsToken) // skip var key word
				vs, err := this.parseVar()
				if err != null {
					this.consume(untilSemicolonOrLf)
					this.Next(lfNotToken)
					continue
				}
				isPublic := isPublic()
				e := new ast.Expression()
				e.Type = ast.ExpressionTypeVar
				e.data = vs
				e.pos = pos
				e.isPublic = isPublic
				e.isGlobal = true
				e.op = "var"
				this.tops.append( new ast.TopNode(e))
				resetProperty()
			case lex.TokenEnum:
				e, err := this.EnumParser.parse()
				if err != null {
					resetProperty()
					continue
				}
				e.comment = comment.comment
				isPublic := isPublic()
				if isPublic {
					e.accessFlags |= cg.AccClassPublic
				}
				if e != null {
					this.tops.append( new ast.TopNode(e))
				}
				resetProperty()
			case lex.TokenFn:
				f, err := this.FunctionParser.parse(true, false)
				if err != null {
					this.Next(lfNotToken)
					continue
				}
				f.comment = comment.comment
				isPublic := isPublic()
				if isPublic {
					f.accessFlags |= cg.AccMethodPublic
				}
				this.tops.append( new ast.TopNode(f))
				resetProperty()
			case lex.TokenLc:
				b := new ast.Block()
				this.Next(lfNotToken) // skip {
				this.BlockParser.parseStatementList(b, true)
				if this.token.Type != lex.TokenRc {
					this.errs.append( new error(sprintf("%s expect '}', but '%s'",
						this.errMsgPrefix(), this.token.Description)))
					this.consume(untilRc)
				}
				this.Next(lfNotToken) // skip }
				this.tops.append( new ast.TopNode(b))

			case lex.TokenClass, lex.TokenInterface:
				c, err := this.ClassParser.parse(isAbstract)
				if err != null {
					resetProperty()
					continue
				}
				c.comment = comment.comment
				this.tops.append( new ast.TopNode( c) )
				isPublic := isPublic()
				if isPublic {
					c.accessFlags |= cg.AccClassPublic
				}
				if isAbstract {
					c.accessFlags |= cg.AccClassAbstract
				}
				if isFinal {
					c.accessFlags |= cg.AccClassFinal
					c.finalPos = finalPos
				}
				resetProperty()
			case lex.TokenConst:
				this.Next(lfIsToken) // skip const key word
				cs, err := this.parseConst()
				if err != null {
					this.consume(untilSemicolonOrLf)
					this.Next(lfNotToken)
					resetProperty()
					continue
				}
				isPublic := isPublic()
				for _, v := range cs {
					if isPublic {
						v.accessFlags |= cg.AccFieldPublic
					}
					this.tops.append( new ast.TopNode(v))
				}
				resetProperty()
				continue
			case lex.TokenTypeAlias:
				a, err := this.parseTypeAlias(comment)
				if err != null {
					this.consume(untilSemicolonOrLf)
					this.Next(lfNotToken)
					resetProperty()
					continue
				}
				this.tops.append( new ast.TopNode(a))
			case lex.TokenImport:
				pos := this.mkPos()
				this.parseImports()
				this.errs.append( new error(sprintf("%s cannot have import at this scope",
					this.errMsgPrefix(pos))))
			case lex.TokenEof:
				break
			default:
				if this.ExpressionParser.looksLikeExpression() {
					e, err := this.ExpressionParser.parseExpression(true)
					if err != null {
						continue
					}
					e.isPublic = isPublic()
					e.isGlobal = true
					this.tops.append( new ast.TopNode( e))
				} else {
					this.errs.append( new error(sprintf("%s token '%s' is not except",
						this.errMsgPrefix(), this.token.Description)))
					this.Next(lfNotToken)
				}
			}
		}
		return this.errs
	}

	fn validAfterPublic() -> (err error) {
		if this.token.Type == lex.TokenFn ||
			this.token.Type == lex.TokenClass ||
			this.token.Type == lex.TokenEnum ||
			this.token.Type == lex.TokenIdentifier ||
			this.token.Type == lex.TokenInterface ||
			this.token.Type == lex.TokenConst ||
			this.token.Type == lex.TokenVar ||
			this.token.Type == lex.TokenFinal ||
			this.token.Type == lex.TokenAbstract {
			return null
		}
		err = new error(sprintf("%s cannot have token '%s' after 'public'",
			this.errMsgPrefix(), this.token.Description))
		this.errs.append( err)
		return err
	}
	fn validAfterAbstract() -> (err error) {
		if this.token.Type == lex.TokenClass {
			return null
		}
		err = new error(sprintf("%s cannot have token '%s' after 'abstract'",
			this.errMsgPrefix(), this.token.Description))
		this.errs.append( err)
		return err
	}
	fn validAfterFinal() -> (err error) {
		if this.token.Type == lex.TokenClass ||
			this.token.Type == lex.TokenInterface {
			return null
		}
		err = new error(sprintf("%s cannot have token '%s' after 'final'",
			this.errMsgPrefix(), this.token.Description))
		this.errs.append( err)
		return err
	}

	/*
		statement ending
	*/
	fn isStatementEnding() ->(is bool) {
		return this.token.Type == lex.TokenSemicolon ||
			this.token.Type == lex.TokenLf ||
			this.token.Type == lex.TokenRc ||
			this.token.Type == lex.TokenComment ||
			this.token.Type == lex.TokenMultiLineComment
	}
	fn validStatementEnding() -> (err error) {
		if this.isStatementEnding() {
			return null
		}
		err = new error(sprintf("%s expect semicolon or new line", this.errMsgPrefix()))
		this.errs.append(err)
		return err
	}

	fn mkPos() -> (pos ast.Pos) {
		if this.token != null {
		    pos = new ast.Pos()
		    pos.filename = this.filename
		    pos.line = this.token.EndLine
		    pos.column = this.token.EndColumn
		    pos.offset = this.lexer.GetOffSet()
			return
		} else {
			line, column := this.lexer.GetLineAndColumn()
			pos = new  ast.Pos()
			pos.filename = this.filename
			pos.line = line
			pos.column = column
			return
		}
	}
    /*
	fn mkEndPos() -> (pos ast.Pos) {
		if this.lastToken == null {
			return &ast.Pos{
				filename: this.filename,
				line:     this.token.EndLine,
				column:   this.token.EndColumn,
				offset:   this.lexer.GetOffSet(),
			}
		} else {
			return &ast.Pos{
				filename: this.filename,
				line:     this.lastToken.EndLine,
				column:   this.lastToken.EndColumn,
			}
		}
	}
    */
	// str := "hello world"   a,b = 123 or a b ;
	fn parseConst() -> (constants []ast.Constant, err error) {
		names, err := this.parseNameList()
		if err != null {
			return
		}
		constants = new []ast.Constant(len(names))
		for k, v := range names {
			vd := new ast.Constant()
			vd.name = v.name
			vd.pos = v.pos
			constants[k] = vd
		}
		var variableType ast.Type
		if this.TypeParser.isValidTypeBegin() {
			variableType, err = this.parseType()
			if err != null {
				return
			}
		}
		if variableType != null {
			for _, c := range constants {
				c.Type = variableType.Clone()
			}
		}
		if this.token.Type != lex.TokenAssign {
			err = new error(sprintf("%s missing assign", this.errMsgPrefix()))
			this.errs.append( err)
			return
		}
		this.Next(lfNotToken) // skip =
		es, err := this.ExpressionParser.parseExpressions(lex.TokenSemicolon)
		if err != null {
			return
		}
		if len(es) != len(constants) {
			err = new error(sprintf("%s cannot assign %d value to %d constant",
				this.errMsgPrefix(), len(es), len(constants)))
			this.errs.append( err)
		}
		for k, _ := range constants {
			if k < len(es) {
				constants[k].defaultValueExpression = es[k]
			}
		}
		return
	}

	// str := "hello world"   a,b = 123 or a b ;
	fn parseVar() -> (ret ast.ExpressionVar, err error) {
		names, err := this.parseNameList()
		if err != null {
			return
		}
		ret = new ast.ExpressionVar()
		ret.Variables = new []ast.Variable(len(names))
		for k, v := range names {
			vd := new ast.Variable()
			vd.name = v.name
			vd.pos = v.pos
			ret.Variables[k] = vd
		}
		if this.token.Type != lex.TokenAssign {
			ret.Type, err = this.parseType()
			if err != null {
				return
			}
		}
		if this.token.Type == lex.TokenAssign {
			this.Next(lfNotToken) // skip = or :=
			ret.InitValues, err = this.ExpressionParser.parseExpressions(lex.TokenSemicolon)
			if err != null {
				return
			}
		}
		return
	}

	fn Next(lfIsToken bool) {
		if this.consumeFoundValidToken {
			this.consumeFoundValidToken = false
			return
		}
		var err error
		var tok lex.Token
		this.lastToken = this.token
		defer {
			if this.lastToken == null {
				this.lastToken = this.token
			}
		}
		for {
			tok, err = this.lexer.Next()
			if tok != null {
				this.token = tok
			}
			if err != null {
				this.errs.append(
					new error(sprintf("%s %s", this.errMsgPrefix(), err.getMessage())))
			}
			if tok == null {
				continue
			}
			this.token = tok
			if lfIsToken {
				break
			}
			if tok.Type != lex.TokenLf {
				break
			}
		}
		return
	}

	/*
		pos.errMsgPrefix() only receive one argument
	*/
	fn errMsgPrefix(pos ast.Pos...) -> (prefix string) {
		if len(pos) > 0 {
			return pos[0].errMsgPrefix()
		}
		return this.mkPos().errMsgPrefix()
	}

	fn consume(until map{lex.TokenKind -> bool } ) {
		if len(until) == 0 {
			panic("no token to consume")
		}
		for this.token.Type != lex.TokenEof {
			if this.token.Type == lex.TokenPublic ||
				this.token.Type == lex.TokenProtected ||
				this.token.Type == lex.TokenPrivate ||
				this.token.Type == lex.TokenClass ||
				this.token.Type == lex.TokenInterface ||
				this.token.Type == lex.TokenFn ||
				this.token.Type == lex.TokenFor ||
				this.token.Type == lex.TokenIf ||
				this.token.Type == lex.TokenSwitch ||
				this.token.Type == lex.TokenEnum ||
				this.token.Type == lex.TokenConst ||
				this.token.Type == lex.TokenVar ||
				this.token.Type == lex.TokenImport ||
				this.token.Type == lex.TokenTypeAlias ||
				this.token.Type == lex.TokenGoto ||
				this.token.Type == lex.TokenBreak ||
				this.token.Type == lex.TokenContinue ||
				this.token.Type == lex.TokenDefer ||
				this.token.Type == lex.TokenReturn ||
				this.token.Type == lex.TokenPass ||
				this.token.Type == lex.TokenExtends ||
				this.token.Type == lex.TokenImplements ||
				this.token.Type == lex.TokenGlobal ||
				this.token.Type == lex.TokenCase ||
				this.token.Type == lex.TokenDefault {
				if until.keyExist(this.token.Type) == false {
					this.consumeFoundValidToken = true
					return
				}
			}
			if this.token.Type == lex.TokenLc {
				if until.keyExist(lex.TokenLc) == false {
					this.consumeFoundValidToken = true
					return
				}
			}
			if this.token.Type == lex.TokenRc {
				if until.keyExist(lex.TokenRc) == false {
					this.consumeFoundValidToken = true
					return
				}
			}
			if until.keyExist(this.token.Type) {
				return
			}
			this.Next(lfIsToken)
		}
	}

	fn ifTokenIsLfThenSkip() {
		if this.token.Type == lex.TokenLf {
			this.Next(lfNotToken)
		}
	}

	fn unExpectNewLineAndSkip() {
		if err := this.unExpectNewLine(); err != null {
			this.Next(lfNotToken)
		}
	}
	fn unExpectNewLine() -> (err error) {
		if this.token.Type == lex.TokenLf {
			err = new error(sprintf("%s unexpected new line",
				this.errMsgPrefix(this.mkPos())))
			this.errs.append( err)
		}
		return err
	}
	fn expectNewLineAndSkip() {
		if err := this.expectNewLine(); err == null {
			this.Next(lfNotToken)
		}
	}
	fn expectNewLine() -> (err error)  {
		if this.token.Type != lex.TokenLf &&
			this.token.Type != lex.TokenComment {
			err = new error(sprintf("%s expect new line , but '%s'",
				this.errMsgPrefix(), this.token.Description))
			this.errs.append( err)
		}
		return err
	}

	fn parseTypeAlias(comment CommentParser) -> (alias ast.TypeAlias, err error) {
		this.Next(lfIsToken) // skip type key word
		this.unExpectNewLineAndSkip()
		if this.token.Type != lex.TokenIdentifier {
			err := new error(sprintf("%s expect identifer,but '%s'", this.errMsgPrefix(), this.token.Description))
			this.errs.append( err)
			return null, err
		}
		ret := new ast.TypeAlias()
		ret.pos = this.mkPos()
		ret.name = this.token.stringValue
		this.Next(lfIsToken) // skip identifier
		if this.token.Type != lex.TokenAssign {
			err := new error(sprintf("%s expect '=',but '%s'", this.errMsgPrefix(), this.token.Description))
			this.errs.append( err)
			return null, err
		}
		this.Next(lfNotToken) // skip =
		ret.Type, err = this.parseType()
		if err != null {
			return null, err
		}
		ret.comment = comment.comment
		if this.token.Type == lex.TokenComment {
			this.Next(lfIsToken)
		}
		return ret, err
	}

	/*
		a int
		int
	*/
	fn parseTypedName() -> (vs []ast.Variable, err error) {
		if this.token.Type != lex.TokenIdentifier {
			/*
				not identifier begin
				must be type
				// int
			*/
			t, err := this.parseType()
			if err != null {
				return null, err
			}
			v := new ast.Variable()
			v.Type = t
			v.pos = this.mkPos()
			return []ast.Variable{v}, null
		}
		names, err := this.parseNameList()
		if err != null {
			return null, err
		}
		if this.TypeParser.isValidTypeBegin() {
			/*
				a , b int
			*/
			t, err := this.parseType()
			if err != null {
				return null, err
			}
			vs = new []ast.Variable(len(names))
			for k, v := range names {
				vd := new ast.Variable()
				vs[k] = vd
				vd.name = v.name
				vd.pos = v.pos
				vd.Type = t.Clone()
				vd.Type.pos = v.pos // override pos
			}
			return vs, null
		} else {
			/*
				syntax a,b
				not valid type after name list, "a" and "b" must indicate types
			*/

			vs = new []ast.Variable(len(names))
			for k, v := range names {
				vd := new ast.Variable()
				vs[k] = vd
				vd.pos = v.pos
				vd.Type = new ast.Type()
				vd.Type.Type = ast.VariableTypeName
				vd.Type.pos = v.pos
				vd.Type.name = v.name
				vd.Type.pos = v.pos // override pos
			}
			return vs, null
		}
	}

	// a,b int or int,bool  c xxx
	fn parseTypedNames() -> (vs []ast.Variable, err error) {
		vs = []ast.Variable{}
		for this.token.Type != lex.TokenEof {
			ns, err := this.parseNameList()
			if err != null {
				return vs, err
			}
			t, err := this.parseType()
			if err != null {
				return vs, err
			}
			for _, v := range ns {
				vd := new ast.Variable()
				vd.name = v.name
				vd.pos = v.pos
				vd.Type = t.Clone()
				vs.append(vd)
			}
			if this.token.Type != lex.TokenComma { // not a comma
				break
			} else {
				this.Next(lfNotToken)
			}
		}
		return vs, null
	}


 
	fn parseImports() -> (imports []ast.Import = []ast.Import{}) {
		for this.token.Type == lex.TokenImport ||
			this.token.Type == lex.TokenComment ||
			this.token.Type == lex.TokenMultiLineComment {
			if this.token.Type == lex.TokenComment ||
				this.token.Type == lex.TokenMultiLineComment {
				this.Next(lfNotToken)
				continue
			}
			this.Next(lfIsToken) // skip import key word
			this.unExpectNewLineAndSkip()
			if this.token.Type != lex.TokenLiteralString {
				this.errs.append( new error(sprintf("%s expect 'package' after import,but '%s'",
					this.errMsgPrefix(), this.token.Description)))
				this.consume(untilSemicolonOrLf)
				this.Next(lfNotToken)
				continue
			}
			i := new ast.Import()
			i.pos = this.mkPos()
			i.Import = this.token.stringValue
			imports.append(i)
			this.Next(lfIsToken) // skip name
			if this.token.Type == lex.TokenAs {
				/*
					import "xxxxxxxxxxx" as yyy
				*/
				this.Next(lfNotToken) // skip as
				if this.token.Type != lex.TokenIdentifier {
					this.errs.append( new error(sprintf("%s expect 'identifier' after 'as',but '%s'",
						this.errMsgPrefix(), this.token.Description)))
					this.consume(untilSemicolonOrLf)
					this.Next(lfNotToken)
					continue
				} else {
					i.alias = this.token.stringValue
					this.Next(lfIsToken) // skip identifier
				}
			}
			this.validStatementEnding()
			this.Next(lfNotToken)
		}
	}

	//at least one name
	fn parseNameList() -> (names []ast.NameWithPos, err error) {
		if this.token.Type != lex.TokenIdentifier {
			err = new error(sprintf("%s expect identifier,but '%s'",
				this.errMsgPrefix(), this.token.Description))
			this.errs.append( err)
			return null, err
		}
		names = []ast.NameWithPos{}
		for this.token.Type == lex.TokenIdentifier {
			t := new ast.NameWithPos(this.token.stringValue,this.mkPos())
			assert(t.pos != null)
			names.append(t)
			this.Next(lfIsToken)
			if this.token.Type != lex.TokenComma {
				// not a ,
				break
			} else {
				this.Next(lfNotToken) // skip comma
				if this.token.Type != lex.TokenIdentifier {
					err = new error(sprintf("%s not a 'identifier' after a comma,but '%s'",
						this.errMsgPrefix(), this.token.Description))
					this.errs.append( err)
					return names, err
				}
			}
		}
		return
	}

	fn parseType() -> (ret ast.Type,err error) {
		return this.TypeParser.parseType()
	}
	fn parseTypes(endTokens lex.TokenKind...) ->(ts []ast.Type,err error) {
		return this.TypeParser.parseTypes()
	}
}


