import "lucy/cmd/langtools/compile/ast"
import "lucy/cmd/langtools/compile/lex"

public fn Parse(
	tops []ast.TopNode,
	filename string,
	bs []byte,
	onlyParseImport bool,
	nErrors2Stop int) -> (errs []error) {
	p := new Parser()
	p.bs = bs
	p.tops = tops
	p.filename = filename
	p.onlyParseImport = onlyParseImport
	p.nErrors2Stop = nErrors2Stop
	return p.Parse()
}

class Parser {
	onlyParseImport        bool
	bs                     []byte
	tops                   []ast.TopNode
	lexer                  lex.Lexer
	filename               string
	lastToken              lex.Token
	token                  lex.Token
	errs                   []error
	nErrors2Stop           int
	consumeFoundValidToken bool
	ExpressionParser       ExpressionParser
	FunctionParser         FunctionParser
	ClassParser            ClassParser
	BlockParser            BlockParser
	TypeParser             TypeParser 
	EnumParser             EnumParser


	/*
		call before parse source file
	*/
	fn Parser() {
	    this.super()
		this.ExpressionParser = new ExpressionParser(this)
		this.FunctionParser = new FunctionParser(this)
		this.TypeParser = new TypeParser(this)
		this.ClassParser = new ClassParser(this)
		this.BlockParser = new BlockParser(this)
		this.EnumParser = new EnumParser(this)
	}

	fn parse() -> (errs []error ) {
		this.initParser()
		this.lexer = lex.New(this.bs, 1, 1)
		this.Next(lfNotToken) //
		if this.token.Type == lex.TokenEof {
			return null
		}
		for _, t := range this.parseImports() {
			this.tops.append( new ast.TopNode(t))
		}
		if this.onlyParseImport { // only parse imports
			return this.errs
		}
		var accessControlToken lex.Token
		isFinal := false
		isAbstract := false
		var finalPos ast.Pos
		comment := new CommentParser(this)
		resetProperty := fn() {
			accessControlToken = null
			isFinal = false
			isAbstract = false
			finalPos = null
			comment.reset()
		}
		isPublic := fn() -> (is bool) {
			return accessControlToken != null && accessControlToken.Type == lex.TokenPublic
		}
		for this.token.Type != lex.TokenEof {
			if len(this.errs) > this.nErrors2Stop {
				break
			}
			switch this.token.Type {
			case lex.TokenComment, lex.TokenMultiLineComment:
				comment.read()
			case lex.TokenSemicolon, lex.TokenLf: // empty statement, no big deal
				this.Next(lfNotToken)
				continue
			case lex.TokenPublic:
				accessControlToken = this.token
				this.Next(lfIsToken)
				this.unExpectNewLineAndSkip()
				if err := this.validAfterPublic(); err != null {
					accessControlToken = null
				}
				continue
			case lex.TokenAbstract:
				this.Next(lfIsToken)
				this.unExpectNewLineAndSkip()
				if err := this.validAfterAbstract(); err == null {
					isAbstract = true
				}
			case lex.TokenFinal:
				pos := this.mkPos()
				this.Next(lfIsToken)
				this.unExpectNewLineAndSkip()
				if err := this.validAfterFinal(); err != null {
					isFinal = false
				} else {
					isFinal = true
					finalPos = pos
				}
				continue
			case lex.TokenVar:
				pos := this.mkPos()
				this.Next(lfIsToken) // skip var key word
				vs, err := this.parseVar()
				if err != null {
					this.consume(untilSemicolonOrLf)
					this.Next(lfNotToken)
					continue
				}
				isPublic := isPublic()
				e := new ast.Expression()
				e.Type = ast.ExpressionTypeVar
				e.Data = vs
				e.Pos = pos
				e.IsPublic = isPublic
				e.IsGlobal = true
				e.Op = "var"
				this.tops.append( new ast.TopNode(e))
				resetProperty()
			case lex.TokenEnum:
				e, err := this.EnumParser.parseEnum()
				if err != null {
					resetProperty()
					continue
				}
				e.Comment = comment.Comment
				isPublic := isPublic()
				if isPublic {
					e.AccessFlags |= cg.AccClassPublic
				}
				if e != null {
					this.tops.append( new ast.TopNode(e))
				}
				resetProperty()
			case lex.TokenFn:
				f, err := this.FunctionParser.parse(true, false)
				if err != null {
					this.Next(lfNotToken)
					continue
				}
				f.Comment = comment.Comment
				isPublic := isPublic()
				if isPublic {
					f.AccessFlags |= cg.AccMethodPublic
				}
				this.tops.append( new ast.TopNode(f))
				resetProperty()
			case lex.TokenLc:
				b := new ast.Block()
				this.Next(lfNotToken) // skip {
				this.BlockParser.parseStatementList(b, true)
				if this.token.Type != lex.TokenRc {
					this.errs = append(this.errs, new error(sprintf("%s expect '}', but '%s'",
						this.errMsgPrefix(), this.token.Description)))
					this.consume(untilRc)
				}
				this.Next(lfNotToken) // skip }
				this.tops.append( new ast.TopNode(b))

			case lex.TokenClass, lex.TokenInterface:
				c, err := this.ClassParser.parse(isAbstract)
				if err != null {
					resetProperty()
					continue
				}
				c.Comment = comment.Comment
				this.tops.append( new ast.TopNode( c) )
				isPublic := isPublic()
				if isPublic {
					c.AccessFlags |= cg.AccClassPublic
				}
				if isAbstract {
					c.AccessFlags |= cg.AccClassAbstract
				}
				if isFinal {
					c.AccessFlags |= cg.AccClassFinal
					c.FinalPos = finalPos
				}
				resetProperty()
			case lex.TokenConst:
				this.Next(lfIsToken) // skip const key word
				cs, err := this.parseConst()
				if err != null {
					this.consume(untilSemicolonOrLf)
					this.Next(lfNotToken)
					resetProperty()
					continue
				}
				isPublic := isPublic()
				for _, v := range cs {
					if isPublic {
						v.AccessFlags |= cg.AccFieldPublic
					}
					this.tops.append( new ast.TopNode(v))
				}
				resetProperty()
				continue
			case lex.TokenTypeAlias:
				a, err := this.parseTypeAlias(comment)
				if err != null {
					this.consume(untilSemicolonOrLf)
					this.Next(lfNotToken)
					resetProperty()
					continue
				}
				this.tops.append( new ast.TopNode(a))
			case lex.TokenImport:
				pos := this.mkPos()
				this.parseImports()
				this.errs = append(this.errs, new error(sprintf("%s cannot have import at this scope",
					this.errMsgPrefix(pos))))
			case lex.TokenEof:
				break
			default:
				if this.ExpressionParser.looksLikeExpression() {
					e, err := this.ExpressionParser.parseExpression(true)
					if err != null {
						continue
					}
					e.IsPublic = isPublic()
					e.IsGlobal = true
					this.tops.append( new ast.TopNode( e))
				} else {
					this.errs = append(this.errs, new error(sprintf("%s token '%s' is not except",
						this.errMsgPrefix(), this.token.Description)))
					this.Next(lfNotToken)
				}
			}
		}
		return this.errs
	}

	fn validAfterPublic() -> (err error) {
		if this.token.Type == lex.TokenFn ||
			this.token.Type == lex.TokenClass ||
			this.token.Type == lex.TokenEnum ||
			this.token.Type == lex.TokenIdentifier ||
			this.token.Type == lex.TokenInterface ||
			this.token.Type == lex.TokenConst ||
			this.token.Type == lex.TokenVar ||
			this.token.Type == lex.TokenFinal ||
			this.token.Type == lex.TokenAbstract {
			return null
		}
		err = new error(sprintf("%s cannot have token '%s' after 'public'",
			this.errMsgPrefix(), this.token.Description))
		this.errs = append(this.errs, err)
		return err
	}
	fn validAfterAbstract() -> (err error) {
		if this.token.Type == lex.TokenClass {
			return null
		}
		err = new error(sprintf("%s cannot have token '%s' after 'abstract'",
			this.errMsgPrefix(), this.token.Description))
		this.errs = append(this.errs, err)
		return err
	}
	fn validAfterFinal() -> (err error) {
		if this.token.Type == lex.TokenClass ||
			this.token.Type == lex.TokenInterface {
			return null
		}
		err = new error(sprintf("%s cannot have token '%s' after 'final'",
			this.errMsgPrefix(), this.token.Description))
		this.errs = append(this.errs, err)
		return err
	}

	/*
		statement ending
	*/
	fn isStatementEnding() ->(is bool) {
		return this.token.Type == lex.TokenSemicolon ||
			this.token.Type == lex.TokenLf ||
			this.token.Type == lex.TokenRc ||
			this.token.Type == lex.TokenComment ||
			this.token.Type == lex.TokenMultiLineComment
	}
	fn validStatementEnding() -> (err error) {
		if this.isStatementEnding() {
			return null
		}
		token := this.token
		err = new error(sprintf("%s expect semicolon or new line", this.errMsgPrefix()))
		this.errs = append(this.errs, err)
		return null
	}

	fn mkPos() -> (pos ast.Pos) {
		if this.token != null {
		    pos := new ast.Pos()
		    pos.Filename = this.filename
		    pos.Line = this.token.EndLine
		    pos.Column = this.token.EndColumn
		    pos.Offset = this.lexer.GetOffSet()
			return
		} else {
			line, column := this.lexer.GetLineAndColumn()
			pos = new  ast.Pos()
			pos.Filename = this.filename
			pos.Line = line
			pos.Column = column
			return
		}
	}
    /*
	fn mkEndPos() -> (pos ast.Pos) {
		if this.lastToken == null {
			return &ast.Pos{
				Filename: this.filename,
				Line:     this.token.EndLine,
				Column:   this.token.EndColumn,
				Offset:   this.lexer.GetOffSet(),
			}
		} else {
			return &ast.Pos{
				Filename: this.filename,
				Line:     this.lastToken.EndLine,
				Column:   this.lastToken.EndColumn,
			}
		}
	}
    */
	// str := "hello world"   a,b = 123 or a b ;
	fn parseConst() -> (constants []ast.Constant, err error) {
		names, err := this.parseNameList()
		if err != null {
			return
		}
		constants = new []ast.Constant(len(names))
		for k, v := range names {
			vd := new ast.Constant()
			vd.Name = v.Name
			vd.Pos = v.Pos
			constants[k] = vd
		}
		var variableType ast.Type
		if this.isValidTypeBegin() {
			variableType, err = this.parseType()
			if err != null {
				return
			}
		}
		if variableType != null {
			for _, c := range constants {
				c.Type = variableType.Clone()
			}
		}
		if this.token.Type != lex.TokenAssign {
			err = new error(sprintf("%s missing assign", this.errMsgPrefix()))
			this.errs = append(this.errs, err)
			return
		}
		this.Next(lfNotToken) // skip =
		es, err := this.ExpressionParser.parseExpressions(lex.TokenSemicolon)
		if err != null {
			return
		}
		if len(es) != len(constants) {
			err = new error(sprintf("%s cannot assign %d value to %d constant",
				this.errMsgPrefix(), len(es), len(constants)))
			this.errs = append(this.errs, err)
		}
		for k, _ := range constants {
			if k < len(es) {
				constants[k].DefaultValueExpression = es[k]
			}
		}
		return
	}

	// str := "hello world"   a,b = 123 or a b ;
	fn parseVar() -> (ret ast.ExpressionVar, err error) {
		names, err := this.parseNameList()
		if err != null {
			return
		}
		ret = new ast.ExpressionVar()
		ret.Variables = new []ast.Variable(len(names))
		for k, v := range names {
			vd := new ast.Variable()
			vd.Name = v.Name
			vd.Pos = v.Pos
			ret.Variables[k] = vd
		}
		if this.token.Type != lex.TokenAssign {
			ret.Type, err = this.parseType()
			if err != null {
				return
			}
		}
		if this.token.Type == lex.TokenAssign {
			this.Next(lfNotToken) // skip = or :=
			ret.InitValues, err = this.ExpressionParser.parseExpressions(lex.TokenSemicolon)
			if err != null {
				return
			}
		}
		return
	}

	fn Next(lfIsToken bool) {
		if this.consumeFoundValidToken {
			this.consumeFoundValidToken = false
			return
		}
		var err error
		var tok lex.Token
		this.lastToken = this.token
		defer {
			if this.lastToken == null {
				this.lastToken = this.token
			}
		}
		for {
			tok, err = this.lexer.Next()
			if tok != null {
				this.token = tok
			}
			if err != null {
				this.errs = append(this.errs,
					new error(sprintf("%s %s", this.errMsgPrefix(), err.Error())))
			}
			if tok == null {
				continue
			}
			this.token = tok
			if lfIsToken {
				break
			}
			if tok.Type != lex.TokenLf {
				break
			}
		}
		return
	}

	/*
		pos.ErrMsgPrefix() only receive one argument
	*/
	fn errMsgPrefix(pos ast.Pos...) -> (prefix string) {
		if len(pos) > 0 {
			return pos[0].ErrMsgPrefix()
		}
		return this.mkPos().ErrMsgPrefix()
	}

	fn consume(until map{lex.TokenKind -> bool } ) {
		if len(until) == 0 {
			panic("no token to consume")
		}
		for this.token.Type != lex.TokenEof {
			if this.token.Type == lex.TokenPublic ||
				this.token.Type == lex.TokenProtected ||
				this.token.Type == lex.TokenPrivate ||
				this.token.Type == lex.TokenClass ||
				this.token.Type == lex.TokenInterface ||
				this.token.Type == lex.TokenFn ||
				this.token.Type == lex.TokenFor ||
				this.token.Type == lex.TokenIf ||
				this.token.Type == lex.TokenSwitch ||
				this.token.Type == lex.TokenEnum ||
				this.token.Type == lex.TokenConst ||
				this.token.Type == lex.TokenVar ||
				this.token.Type == lex.TokenImport ||
				this.token.Type == lex.TokenTypeAlias ||
				this.token.Type == lex.TokenGoto ||
				this.token.Type == lex.TokenBreak ||
				this.token.Type == lex.TokenContinue ||
				this.token.Type == lex.TokenDefer ||
				this.token.Type == lex.TokenReturn ||
				this.token.Type == lex.TokenPass ||
				this.token.Type == lex.TokenExtends ||
				this.token.Type == lex.TokenImplements ||
				this.token.Type == lex.TokenGlobal ||
				this.token.Type == lex.TokenCase ||
				this.token.Type == lex.TokenDefault {
				if _, ok := until[this.token.Type]; ok == false {
					this.consumeFoundValidToken = true
					return
				}
			}
			if this.token.Type == lex.TokenLc {
				if _, ok := until[lex.TokenLc]; ok == false {
					this.consumeFoundValidToken = true
					return
				}
			}
			if this.token.Type == lex.TokenRc {
				if _, ok := until[lex.TokenRc]; ok == false {
					this.consumeFoundValidToken = true
					return
				}
			}
			if _, ok := until[this.token.Type]; ok {
				return
			}
			this.Next(lfIsToken)
		}
	}

	fn ifTokenIsLfThenSkip() {
		if this.token.Type == lex.TokenLf {
			this.Next(lfNotToken)
		}
	}

	fn unExpectNewLineAndSkip() {
		if err := this.unExpectNewLine(); err != null {
			this.Next(lfNotToken)
		}
	}
	fn unExpectNewLine() -> (err error) {
		if this.token.Type == lex.TokenLf {
			err = new error(sprintf("%s unexpected new line",
				this.errMsgPrefix(this.mkPos())))
			this.errs = append(this.errs, err)
		}
		return err
	}
	fn expectNewLineAndSkip() {
		if err := this.expectNewLine(); err == null {
			this.Next(lfNotToken)
		}
	}
	fn expectNewLine() -> (err error)  {
		var err error
		if this.token.Type != lex.TokenLf &&
			this.token.Type != lex.TokenComment {
			err = new error(sprintf("%s expect new line , but '%s'",
				this.errMsgPrefix(), this.token.Description))
			this.errs = append(this.errs, err)
		}
		return err
	}

	fn parseTypeAlias(comment CommentParser) -> (alias ast.TypeAlias, err error) {
		this.Next(lfIsToken) // skip type key word
		this.unExpectNewLineAndSkip()
		if this.token.Type != lex.TokenIdentifier {
			err := new error(sprintf("%s expect identifer,but '%s'", this.errMsgPrefix(), this.token.Description))
			this.errs = append(this.errs, err)
			return null, err
		}
		ret := new ast.TypeAlias()
		ret.Pos = this.mkPos()
		ret.Name = this.token.Data.(string)
		this.Next(lfIsToken) // skip identifier
		if this.token.Type != lex.TokenAssign {
			err := new error(sprintf("%s expect '=',but '%s'", this.errMsgPrefix(), this.token.Description))
			this.errs = append(this.errs, err)
			return null, err
		}
		this.Next(lfNotToken) // skip =
		var err error
		ret.Type, err = this.parseType()
		if err != null {
			return null, err
		}
		ret.Comment = comment.Comment
		if this.token.Type == lex.TokenComment {
			this.Next(lfIsToken)
		}
		return ret, err
	}

	/*
		a int
		int
	*/
	fn parseTypedName() -> (vs []ast.Variable, err error) {
		if this.token.Type != lex.TokenIdentifier {
			/*
				not identifier begin
				must be type
				// int
			*/
			t, err := this.parseType()
			if err != null {
				return null, err
			}
			v := new ast.Variable()
			v.Type = t
			v.Pos = this.mkPos()
			return []ast.Variable{v}, null
		}
		names, err := this.parseNameList()
		if err != null {
			return null, err
		}
		if this.isValidTypeBegin() {
			/*
				a , b int
			*/
			t, err := this.parseType()
			if err != null {
				return null, err
			}
			vs = new []ast.Variable(len(names))
			for k, v := range names {
				vd := new ast.Variable()
				vs[k] = vd
				vd.Name = v.Name
				vd.Pos = v.Pos
				vd.Type = t.Clone()
				vd.Type.Pos = v.Pos // override pos
			}
			return vs, null
		} else {
			/*
				syntax a,b
				not valid type after name list, "a" and "b" must indicate types
			*/

			vs = new []ast.Variable(len(names))
			for k, v := range names {
				vd := new ast.Variable()
				vs[k] = vd
				vd.Pos = v.Pos
				vd.Type = new ast.Type()
				vd.Type.Type = ast.VariableTypeName
				vd.Type.Pos = v.Pos
				vd.Type.Name = v.Name
				vd.Type.Pos = v.Pos // override pos
			}
			return vs, null
		}
	}

	// a,b int or int,bool  c xxx
	fn parseTypedNames() -> (vs []ast.Variable, err error) {
		vs = []ast.Variable{}
		for this.token.Type != lex.TokenEof {
			ns, err := this.parseNameList()
			if err != null {
				return vs, err
			}
			t, err := this.parseType()
			if err != null {
				return vs, err
			}
			for _, v := range ns {
				vd := new ast.Variable()
				vd.Name = v.Name
				vd.Pos = v.Pos
				vd.Type = t.Clone()
				vs = append(vs, vd)
			}
			if this.token.Type != lex.TokenComma { // not a comma
				break
			} else {
				this.Next(lfNotToken)
			}
		}
		return vs, null
	}


 
	fn parseImports() -> (imports []ast.Import = []ast.Import{}) {
		for this.token.Type == lex.TokenImport ||
			this.token.Type == lex.TokenComment ||
			this.token.Type == lex.TokenMultiLineComment {
			if this.token.Type == lex.TokenComment ||
				this.token.Type == lex.TokenMultiLineComment {
				this.Next(lfNotToken)
				continue
			}
			this.Next(lfIsToken) // skip import key word
			this.unExpectNewLineAndSkip()
			if this.token.Type != lex.TokenLiteralString {
				this.errs = append(this.errs, new error(sprintf("%s expect 'package' after import,but '%s'",
					this.errMsgPrefix(), this.token.Description)))
				this.consume(untilSemicolonOrLf)
				this.Next(lfNotToken)
				continue
			}
			i := new ast.Import()
			i.Pos = this.mkPos()
			i.Import = this.token.Data.(string)
			ret = append(ret, i)
			this.Next(lfIsToken) // skip name
			if this.token.Type == lex.TokenAs {
				/*
					import "xxxxxxxxxxx" as yyy
				*/
				this.Next(lfNotToken) // skip as
				if this.token.Type != lex.TokenIdentifier {
					this.errs = append(this.errs, new error(sprintf("%s expect 'identifier' after 'as',but '%s'",
						this.errMsgPrefix(), this.token.Description)))
					this.consume(untilSemicolonOrLf)
					this.Next(lfNotToken)
					continue
				} else {
					i.Alias = this.token.Data.(string)
					this.Next(lfIsToken) // skip identifier
				}
			}
			this.validStatementEnding()
			this.Next(lfNotToken)
		}
		return ret
	}

	//at least one name
	fn parseNameList() -> (names []ast.NameWithPos, err error) {
		if this.token.Type != lex.TokenIdentifier {
			err = new error(sprintf("%s expect identifier,but '%s'",
				this.errMsgPrefix(), this.token.Description))
			this.errs = append(this.errs, err)
			return null, err
		}
		names = []ast.NameWithPos{}
		for this.token.Type == lex.TokenIdentifier {
			names = append(names, new ast.NameWithPos(this.token.Data.(string),this.mkPos()))
			this.Next(lfIsToken)
			if this.token.Type != lex.TokenComma {
				// not a ,
				break
			} else {
				this.Next(lfNotToken) // skip comma
				if this.token.Type != lex.TokenIdentifier {
					err = new error(sprintf("%s not a 'identifier' after a comma,but '%s'",
						this.errMsgPrefix(), this.token.Description))
					this.errs = append(this.errs, err)
					return names, err
				}
			}
		}
		return
	}

	fn parseType() -> (ret ast.Type,err error) {
		return this.TypeParser.parseType()
	}
	fn parseTypes(endTokens lex.TokenKind...) ->(ts []ast.Type,err error) {
		return this.TypeParser.parseTypes()
	}
}


